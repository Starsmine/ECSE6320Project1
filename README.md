# ECSE 6320 - Advanced Computer Systems Projects

[![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/Starsmine/ECSE6320Project1)

This repository contains four comprehensive projects exploring modern computer architecture, performance analysis, and concurrent programming concepts.

## Projects

### [Project A1: Operating System and CPU Feature Performance Exploration](./ProjectA1/)
Explores performance impacts of OS and CPU microarchitectural features including:
- CPU Affinity and Thread Pinning
- Cache Prefetching (Hardware Prefetchers)
- Simultaneous Multithreading (SMT/Hyperthreading)
- Huge Pages (THP)
- Asynchronous I/O (io_uring with zero-copy)

**Key Results**: io_uring achieves 24Ã— speedup (977 MB/s vs 66 MB/s sync I/O), cache prefetcher shows 3.4Ã— performance gain for sequential access.

[ðŸ“– View Full Documentation](./ProjectA1/README.md)

---

### [Project A2: Dense vs Sparse Matrix Multiplication](./ProjectA2/)
Implements and benchmarks dense matrix multiplication (GEMM) using tiled/blocked algorithms versus sparse matrix multiplication (CSR-SpMM) with SIMD optimizations:
- Performance breakeven analysis (density: 8.5% scalar, 31% SIMD)
- Working-set transitions (cache hierarchy analysis)
- Arithmetic intensity and roofline modeling
- Thread scaling and perf counter analysis

**Key Results**: SIMD SpMM achieves 10.2Ã— speedup. Break-even at 31% density (SIMD) and 8.5% (scalar).

[ðŸ“– View Full Documentation](./ProjectA2/README.md)

---

### [Project A3: Approximate Membership Filters](./ProjectA3/)
Comprehensive implementation and benchmarking of four filter types:
- Blocked Bloom Filter (best throughput: 62.8 Mops/s)
- XOR Filter (best space: 9.84 BPE, bit-packed)
- Cuckoo Filter (dynamic with deletes, 2Ã— faster than Quotient at high load)
- Quotient Filter (dynamic with contiguous runs)

**Key Results**: XOR filter achieves 9.84 bits per entry. Bloom filter shows 3.19Ã— thread scaling. SMT degradation observed at 16 threads.

[ðŸ“– View Full Documentation](./ProjectA3/README.md)

---

### [Project A4: Concurrent Data Structures and Memory Coherence](./ProjectA4/)
Thread-safe hash table with synchronization strategy comparison:
- Coarse-grained locking (single global mutex)
- Fine-grained locking (per-bucket locks, 10K mutexes)
- Cache coherence effects and false sharing analysis
- Amdahl's Law validation

**Key Results**: Fine-grained achieves 7.0Ã— speedup (lookup, 16 threads). Coarse-grained shows negative scaling (0.34Ã— at 16 threads due to contention).

[ðŸ“– View Full Documentation](./ProjectA4/README.md)

---

## System Configuration

All benchmarks were conducted on:

### Hardware
- **CPU**: AMD Ryzen 7 7700X (Zen 4 architecture)
  - 8 cores / 16 threads (SMT enabled)
  - Base Clock: 4.5 GHz, Boost Clock: 5.4 GHz
  - **Cache**: L1d: 32 KB Ã— 8, L2: 1 MB Ã— 8, L3: 32 MB (shared)
  - **AVX-512**: Double-pumped (2 cycles per 512-bit operation)
- **Memory**: DDR5-6000 (dual-channel, 48 GB)
- **Storage**: 
  - System: PNY CS3140 1TB NVMe SSD (PCIe Gen4)
  - Secondary: ADATA XPG GAMMIX S70 1TB NVMe SSD (PCIe Gen4)

### Software
- **OS**: Ubuntu 24.04.3 LTS (Noble Numbat)
- **Kernel**: 6.14.0-37-generic
- **Compiler**: GCC 13.3.0 (Ubuntu 13.3.0-6ubuntu2~24.04)
- **Build Flags**: `-O3 -march=native -fopenmp` (project-specific variations)
- **Libraries**:
  - OpenBLAS (ProjectA2 validation)
  - liburing (ProjectA1 async I/O)
  - xxHash (ProjectA3 hashing)
  - 
## Repository Structure

```
FPA2/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ ProjectA1/                   # OS/CPU Feature Exploration
â”‚   â”œâ”€â”€ main.cpp                 # 5 benchmark implementations
â”‚   â”œâ”€â”€ plot_results.py          # Plotting script
â”‚   â”œâ”€â”€ benchmark_results.txt    # Aggregated results
â”‚   â””â”€â”€ README.md                # Full documentation
â”œâ”€â”€ ProjectA2/                   # Dense vs Sparse Matrix Multiplication
â”‚   â”œâ”€â”€ main.cpp                 # GEMM + CSR-SpMM implementations
â”‚   â”œâ”€â”€ run_benchmarks.py        # Automated benchmark suite
â”‚   â”œâ”€â”€ analyze_results.py       # Analysis and plotting
â”‚   â”œâ”€â”€ results/                 # 82 benchmark result files
â”‚   â””â”€â”€ README.md                # Full documentation
â”œâ”€â”€ ProjectA3/                   # Approximate Membership Filters
â”‚   â”œâ”€â”€ main.cpp                 # 4 filter implementations
â”‚   â”œâ”€â”€ run_benchmarks.py        # Benchmark orchestration
â”‚   â”œâ”€â”€ analyze_results.py       # Plotting script
â”‚   â”œâ”€â”€ results/                 # 860 benchmark result files
â”‚   â””â”€â”€ README.md                # Full documentation
â””â”€â”€ ProjectA4/                   # Concurrent Hash Tables
    â”œâ”€â”€ main.cpp                 # Coarse + fine-grained implementations
    â”œâ”€â”€ run_benchmarks.py        # Benchmark suite with perf counters
    â”œâ”€â”€ analyze_results.py       # Analysis and plotting
    â”œâ”€â”€ results/                 # 450 benchmark result files
    â””â”€â”€ README.md                # Full documentation
```

## Building All Projects

Each project includes a `Makefile` for easy compilation:

```bash
# Build all projects
for project in ProjectA1 ProjectA2 ProjectA3 ProjectA4; do
    cd $project && make && cd ..
done

# Or build individually
cd ProjectA1 && make
cd ProjectA2 && make
cd ProjectA3 && make
cd ProjectA4 && make
```

## Running Benchmarks

Each project includes automated benchmark scripts:

```bash
# ProjectA1: Run all 5 benchmarks
cd ProjectA1 && ./os_features_bench

# ProjectA2: Full benchmark suite (82 configs, ~30 min)
cd ProjectA2 && python3 run_benchmarks.py

# ProjectA3: 4 experiments (860 configs, ~45 min)
cd ProjectA3 && python3 run_benchmarks.py

# ProjectA4: Thread scaling suite (450 configs, ~15 min)
cd ProjectA4 && python3 run_benchmarks.py
```

## Key Insights Across Projects

### Performance Optimization Themes

1. **Memory Access Patterns Matter** (A1, A2, A3)
   - Sequential access: 3.4Ã— faster than random (prefetcher)
   - Cache blocking: Critical for dense GEMM performance
   - Bit-packing: 75% memory reduction in XOR filter

2. **Concurrency Challenges** (A3, A4)
   - Lock granularity: Fine-grained achieves 7Ã— speedup vs coarse (negative scaling)
   - False sharing: Cache line bouncing degrades performance
   - SMT benefits diminish: 16 threads show degradation vs 8 cores

3. **Hardware-Software Co-design** (A1, A2, A4)
   - io_uring zero-copy: 24Ã— speedup through kernel bypass
   - AVX-512 SIMD: 10.2Ã— speedup in sparse matrix operations
   - Cache coherence: +11% miss rate at 16 threads (MESI protocol overhead)

4. **Algorithmic Trade-offs** (A2, A3)
   - Dense vs sparse: Break-even at 31% density (SIMD)
   - Space vs speed: XOR (9.84 BPE) vs Bloom (62.8 Mops/s)
   - Static vs dynamic: XOR fastest but immutable

## Dependencies

Common dependencies across projects:

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install -y \
    build-essential \
    gcc g++ \
    libopenblas-dev \
    liburing-dev \
    libxxhash-dev \
    linux-tools-generic \
    python3 python3-pip

# Python packages
pip3 install matplotlib numpy scipy
```

## Performance Counter Tools

Using `perf` for hardware counter analysis:

```bash
# Enable perf for non-root users
sudo sysctl -w kernel.perf_event_paranoid=-1

# Example: Run with cache miss tracking
perf stat -e cycles,cache-misses,cache-references ./your_benchmark
```


## Contact

- GitHub: [@Starsmine](https://github.com/Starsmine)
- Repository: [ECSE6320Project1](https://github.com/Starsmine/ECSE6320Project1)

---

**Note**: All benchmarks include multiple runs with statistical analysis (mean Â± stddev). Performance results are specific to the hardware/software configuration listed above and may vary on different systems.
